This work has attempted to glean knowledge about how to control hands in Virtual Reality using positional tracking devices. Specifically, it has focused on the issue of how to deal with the conflicts that arise between the position and pose of the user's real hands and the physical constraints that the user might expect the virtual environment they are interacting with to impose on their virtual hands: we have referred to this issue as the Virtual Constraints Problem. Our proposed approach to deal with this problem is to adjust the virtual hands position, rotation and finger pose, deviating from the tracking data and other user input in a way that respects the intentions of the user in order to minimize the loss  of the sense of "presence" as explained in terms of Place Illusion, Plausibility Illusion and Sense of Embodiment, discussed in Chapter \ref{chap:theory}. We referred to ways of controlling hands that work like this as Adjusted Hand Control Models.

The controlled experiments conducted in order to compare an example Adjusted Hand Control Model with an Unadjusted Hand Control Model based on the game Job Simulator showed positive results and, together with the recount of prototyping experiments presented in Chapter \ref{chap:experimentalAnalysis}, could provide guidance as to how to proceed in the future when developing Adjusted Hand Control Models. The test setup was however not perfect and we believe there were confounding factors that might have affected the results. Conducting new experiments after solving some of the discovered issues would produce more reliable results. Alternatively, experiments could be performed following established evaluation techniques developed by other researchers for the purpose of measuring "presence" (see overview in \parencite{Schuemie2001}).

Furthermore, we find that previous research could support the hypothesis that separating the virtual hands from the real body as Adjusted Hand Control Models require might not have a negative impact on "presence". At the same time, other developers have begun to create VR games like Wilson's Heart and Lone Echo that use Adjusted Hand Control Models or at any rate approaches that also separate parts of the virtual body from the real body under certain circumstances. The results shown by these developers are promising at the very least.

\section{Future Work}
\label{sec:futureWork}

There is still much to be done in the context of controlling hands in VR, and even more in the larger problem of controlling virtual bodies, instead of just hands. In terms of avoiding the penetration of virtual objects with the hands, the Adaptive hands relied almost entirely on Unity's physics engine. This is a convenient shortcut for the purpose of experimenting, but observing the results, it seems likely that custom solutions will be the only way to achieve greater control of the behavior of the virtual hands when separated from the real hands' position by virtual obstacles. The Adaptive hands became noticeably unstable in many cases and the rotation adjustment sometimes happens in sudden and unexpected ways that are disagreeable for the user. Alternatively, if access to to the internal functionality of Unity's physics engine were an option, techniques like the ones used in Lone Echo could become easier \parencite{loneEchoVideo}.

Based on the test results, we think that improving the form of the grip of the hands when they grab an object so it is more believable is one of the aspects that could produce the most benefit on its own. Adjustment to the finger positions did not seem to bother any of the testers, but only adjusting the fingers would require the user to be more precise with the hand positioning when grabbing in order to ensure that the fingers can reach the object's surface. An alternative to this is to also adjust the hand position and rotation when necessary so that the fingers can be placed properly on the object. This raises the question of whether this acquired positional and rotational offset should be maintained while the object is held or if the virtual hand should "reach out" to the object and then go back to the position and rotation of the real hands. We take how the hands behave in Wilson's Heart to be a positive sign that this kind of adjustment can work in ways that are not off-putting for users.

The testers also seemed to find that the finger adjustment when hovering over objects with the Adaptive hands enhanced the illusion of touching the virtual objects and improved the experience of performing actions like stroking. The hover adjustments however do take some control away from the user, possibly getting in the way of actions like slapping an object with a flat hand.

Finally, an aspect that has clearly not been explored sufficiently in this work, but that is very relevant for VR - hands being no exception - is the use of multimodal feedback. Besides the ever-present visual information, haptic and sound feedback can become powerful enhacers of the illusions we are after: remember that Place Illusion is bounded by the Sensorimotor Contingencies of the system, in particular, this means that every sense we add to the experience will increase the potential degree of PI we can achieve in a virtual reality experience. Some of the comments from the testers support this: despite the unrefined haptic feedback available in the Adaptive hands, in some interactions it was reported to be satisfying and to even produce a sense of intimacy in specific actions.